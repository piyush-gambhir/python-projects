{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests bs4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fetch_sitemap(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def parse_sitemap(sitemap_content):\n",
    "    root = ET.fromstring(sitemap_content)\n",
    "    return [elem.text for elem in root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}loc')]\n",
    "\n",
    "\n",
    "def filter_urls(urls, pattern):\n",
    "    return [url for url in urls if pattern in url]\n",
    "\n",
    "\n",
    "def fetch_and_parse(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "def is_valid_url(url):\n",
    "    try:\n",
    "        result = urlparse(url)\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def extract_vin_and_images(soup):\n",
    "\n",
    "    # Extract VIN\n",
    "    vin = None\n",
    "    vin_pattern = re.compile(r'[A-HJ-NPR-Z0-9]{17}')\n",
    "    for script in soup.find_all('script'):\n",
    "        if script.string:\n",
    "            match = vin_pattern.search(script.string)\n",
    "            if match:\n",
    "                vin = match.group()\n",
    "                break\n",
    "    print(\"VIN found:\", vin)  # Debug print to show the VIN found\n",
    "\n",
    "    # Extract image URLs\n",
    "    image_elements = soup.select('img[src]')\n",
    "    images = [img['src'] for img in image_elements if 'photos' in img['src']]\n",
    "    print(\"Images found:\", images)  # Debug print to show the images found\n",
    "\n",
    "    return vin, ', '.join(images)\n",
    "\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def download_image(image_url, save_path):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "    try:\n",
    "        response = requests.get(image_url, stream=True,\n",
    "                                headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, 'wb') as out_file:\n",
    "                out_file.write(response.content)\n",
    "            # print(f\"Downloaded {image_url} to {save_path}\")\n",
    "        else:\n",
    "            # print(\n",
    "            #     f\"Failed to download {image_url} - Status code: {response.status_code}\")\n",
    "            pass\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while downloading {image_url}: {str(e)}\")\n",
    "\n",
    "\n",
    "def main(website_url):\n",
    "    parsed_url = urlparse(website_url)\n",
    "    website_name = parsed_url.netloc\n",
    "    base_directory = create_directory(website_name)\n",
    "    sitemap_url = f'https://{website_name}/sitemap.xml'\n",
    "    try:\n",
    "        sitemap_content = fetch_sitemap(sitemap_url)\n",
    "        all_urls = parse_sitemap(sitemap_content)\n",
    "        used_car_urls = filter_urls(all_urls, 'inventory/')\n",
    "\n",
    "        # Save filtered URLs\n",
    "        with open(os.path.join(website_name, 'inventory_car_urls.txt'), 'w') as f:\n",
    "            f.writelines(\"\\n\".join(used_car_urls))\n",
    "\n",
    "        # Process each used car URL for images and VIN\n",
    "        data = []\n",
    "        for url in used_car_urls:\n",
    "            soup = fetch_and_parse(url)\n",
    "            vin, images = extract_vin_and_images(soup)\n",
    "            if images:  # Ensure there are valid images\n",
    "                # Adjust path for data subfolder\n",
    "                vin_directory = os.path.join(website_name, 'data', vin)\n",
    "                create_directory(vin_directory)\n",
    "                for index, image_url in enumerate(images.split(', ')):\n",
    "                    image_name = f\"{index}_{os.path.basename(urlparse(image_url).path)}\"\n",
    "                    save_path = os.path.join(vin_directory, image_name)\n",
    "                    download_image(image_url, save_path)\n",
    "                data.append((vin, images))\n",
    "\n",
    "            # Save data to CSV\n",
    "            if data:\n",
    "                with open(os.path.join(website_name, 'vin_image_data.csv'), 'w', newline='', encoding='utf-8') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(['VIN', 'Image URLs'])\n",
    "                    for vin, images in data:\n",
    "                        writer.writerow([vin, images])\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    website_input_url = 'https://www.almcars.com/'\n",
    "    main(website_input_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
